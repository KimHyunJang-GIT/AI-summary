# -*- coding: utf-8 -*-
"""í”„ë¡œì íŠ¸ ì „ë°˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê³µí†µ í—¬í¼ í•¨ìˆ˜ ëª¨ìŒ."""
import os
import string
import re
from pathlib import Path # Path ì„í¬íŠ¸ ì¶”ê°€
import pandas as pd
from tqdm import tqdm

from src.config import BASE_EXT_MAP, CORPUS_PARQUET, TOPIC_MODEL_PATH, EXCLUDE_DIRS # configì—ì„œ í•„ìš”í•œ ê²½ë¡œ ì„í¬íŠ¸

# ìœ„ì¹˜ í‚¤ì›Œë“œì™€ ì‹¤ì œ ê²½ë¡œ ë¬¸ìì—´ ë§¤í•‘
LOCATION_MAP = {
    "ë‹¤ìš´ë¡œë“œ": "Downloads",
    "ë°”íƒ•í™”ë©´": "Desktop",
}

def get_drives():
    """ì‹œìŠ¤í…œì— ì¡´ì¬í•˜ëŠ” ë“œë¼ì´ë¸Œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    drives = []
    for letter in string.ascii_uppercase:
        drive = f"{letter}:\\"
        if os.path.exists(drive):
            drives.append(drive)
    return drives

def parse_query_and_filters(query: str) -> tuple[str, dict]:
    """ì‚¬ìš©ì ì§ˆì˜ì—ì„œ ê²€ìƒ‰ì–´, ëª…ì‹œì /ì•”ì‹œì  í•„í„°ë¥¼ ë¶„ë¦¬í•©ë‹ˆë‹¤."""
    filters = {}
    temp_query = f" {query} " # ë‹¨ì–´ ê²½ê³„(" ")ë¥¼ ìœ„í•´ ì•ë’¤ì— ê³µë°± ì¶”ê°€

    # 1. ëª…ì‹œì  í•„í„° ì¶”ì¶œ (ì˜ˆ: ext:pdf, title:ë³´ê³ ì„œ)
    explicit_filter_pattern = re.compile(r'(\w+):([^\s]+)')
    for match in reversed(list(explicit_filter_pattern.finditer(temp_query))):
        filters[match.group(1).lower()] = match.group(2)
        temp_query = temp_query[:match.start()] + temp_query[match.end():]

    # 2. ì•”ì‹œì  ìœ„ì¹˜ í•„í„° ì¶”ì¶œ (ì˜ˆ: ë‹¤ìš´ë¡œë“œì— ìˆëŠ”, ë°”íƒ•í™”ë©´ì˜)
    # ìœ„ì¹˜ í‚¤ì›Œë“œ ë’¤ì— ì˜¤ëŠ” ì¡°ì‚¬ë¥¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬ (ì— ìˆëŠ”, ì˜, í´ë”ì˜ ë“±)
    for keyword, path_part in LOCATION_MAP.items():
        location_pattern = re.compile(f' {re.escape(keyword)}(?:ì—|ì˜|í´ë”(?:ì˜|ì—)?)? ')
        if match := location_pattern.search(temp_query):
            filters['path'] = path_part
            temp_query = temp_query.replace(match.group(0), " ", 1)
            break # ì²« ë²ˆì§¸ ìœ„ì¹˜ í‚¤ì›Œë“œë§Œ ì‚¬ìš©

    # 3. ì•”ì‹œì  í™•ì¥ì í•„í„° ì¶”ì¶œ (ì˜ˆ: pdf, ì—‘ì…€ íŒŒì¼)
    ext_map = {keyword: ext for ext, keywords in BASE_EXT_MAP.items() for keyword in keywords}
    ext_map.update({ext: ext for ext in BASE_EXT_MAP}) # ì˜¤íƒ€ ìˆ˜ì •
    
    # ì§ì ‘ì ì¸ í™•ì¥ì (.pdf) ë¨¼ì € ì²˜ë¦¬
    direct_ext_pattern = re.compile(r'\.(\w+)\b', re.IGNORECASE)
    if match := direct_ext_pattern.search(temp_query):
        if (matched_ext := "." + match.group(1).lower()) in ext_map:
            filters['ext'] = ext_map[matched_ext]
            temp_query = temp_query.replace(match.group(0), "", 1)
    
    # í‚¤ì›Œë“œ (pdf, ì—‘ì…€) ì²˜ë¦¬
    if 'ext' not in filters:
        sorted_ext_keywords = sorted([k for k in ext_map if not k.startswith('.')], key=len, reverse=True)
        ext_keyword_regex_parts = [re.escape(k) + r'(?:\s*(?:íŒŒì¼|ë¬¸ì„œ|ìë£Œ))?' for k in sorted_ext_keywords]
        if ext_keyword_regex_parts:
            implicit_ext_keyword_pattern = re.compile(r'\b(' + '|'.join(ext_keyword_regex_parts) + r')\b', re.IGNORECASE)
            if match := implicit_ext_keyword_pattern.search(temp_query):
                matched_keyword = re.sub(r'\s*(?:íŒŒì¼|ë¬¸ì„œ|ìë£Œ)$', '', match.group(1).lower())
                if matched_keyword in ext_map:
                    filters['ext'] = ext_map[matched_keyword]
                    temp_query = temp_query.replace(match.group(0), "", 1)

    # 4. ì•”ì‹œì  ì œëª© í•„í„° ì¶”ì¶œ (ì˜ˆ: ì œëª©ì´ ë³´ê³ ì„œì¸)
    implicit_title_patterns = [re.compile(r'(ì œëª©ì´|ì´ë¦„ì´)\s*(\S+)(?:ì¸|ì¸ë¬¸ì„œ|ì¸íŒŒì¼)?'), re.compile(r'(\S+)(?:ë¼ëŠ”|ì´ë¼ëŠ”)\s*(ì œëª©ì˜|ì´ë¦„ì˜)')]
    for pattern in implicit_title_patterns:
        if match := pattern.search(temp_query):
            filters['title'] = match.group(2) if len(match.groups()) >= 2 else match.group(1)
            temp_query = temp_query.replace(match.group(0), "", 1)
            break

    cleaned_query = re.sub(r'\s+', ' ', temp_query).strip()
    return cleaned_query, filters

def have_all_artifacts() -> bool:
    """í•„ìˆ˜ íŒŒì¼(ì½”í¼ìŠ¤, ëª¨ë¸)ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    return CORPUS_PARQUET.exists() and TOPIC_MODEL_PATH.exists()

def _mask_path(file_path: str) -> str:
    """íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤.
    ì˜ˆ: C:\\Users\\Admin\\Downloads\\document.pdf -> ...\\Downloads\\document.pdf
    """
    p = Path(file_path)
    parts = p.parts
    if len(parts) > 3: # C:\\Users\\Admin\\... ì´ìƒì¼ ê²½ìš°
        return "..." + os.sep + os.sep.join(parts[-3:])
    return file_path

def perform_scan_to_csv(output_path: Path, exts_text: str) -> int:
    """íŒŒì¼ ì‹œìŠ¤í…œì„ ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ ëª©ë¡ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    exts_text: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í™•ì¥ì ë¬¸ìì—´ (ì˜ˆ: ".pdf,.docx")
    """
    file_rows = []
    drives = get_drives()
    current_supported_exts = {e.strip().lower() for e in exts_text.split(",") if e.strip()}

    print(f"ğŸ” Starting scan on drives: {', '.join(drives)}")
    print(f"ğŸš« Excluding directories containing: {', '.join(sorted(list(EXCLUDE_DIRS)))}")

    for drive in drives:
        print(f"Scanning drive {drive}...")
        try:
            for root, dirs, files in tqdm(os.walk(drive, topdown=True), desc=f"Scanning {drive}", unit="files"):
                dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
                for file in files:
                    try:
                        p = Path(root) / file
                        if p.suffix.lower() in current_supported_exts and not any(part in EXCLUDE_DIRS for part in p.parts):
                            stat = p.stat()
                            file_rows.append({
                                'path': str(p),
                                'size': stat.st_size,
                                'mtime': stat.st_mtime
                            })
                    except (FileNotFoundError, PermissionError): continue
        except PermissionError:
            print(f"Could not access {drive}. Skipping.")
            continue
    
    output_path.parent.mkdir(parents=True, exist_ok=True)
    pd.DataFrame(file_rows).to_csv(output_path, index=False, encoding='utf-8')
    print(f"ğŸ“¦ ìŠ¤ìº” ê²°ê³¼ ì €ì¥: {output_path} ({len(file_rows)}ê°œ íŒŒì¼)")
    return len(file_rows)
